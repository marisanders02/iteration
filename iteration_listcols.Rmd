---
title: "Iteration and List Columns"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(echo = TRUE)
```

# Lists 

```{r}
l <- list(
  vec_numeric = 1:4, 
  unif_sample = runif(100), 
  mat = matrix(1:8, nrow = 2, ncol = 4, byrow = TRUE), 
  summary = summary(rnorm(1000))
)

l$mat

l[["mat"]][1,3]

l[[4]]
```


```{r}
list_norm <- 
  list(
    a = rnorm(20, 0, 5), 
    b = rnorm(20, 4, 5),
    c = rnorm(20, 0, 10), 
    d = rnorm(20, 4, 10)
  )

list_norm[["b"]]
```

```{r}
mean_and_sd <- function(x) {
  
  mean_x = mean(x)
  sd_x = sd(x)
  
  output_df = 
    tibble(
      mean = mean_x,
      sd = sd_x
    )
  
  return(output_df)
}
```

Take mean and sd of all samples
```{r}
mean_and_sd(list_norm[["a"]])
mean_and_sd(list_norm[["b"]])
mean_and_sd(list_norm[["c"]])
mean_and_sd(list_norm[["d"]])

```

## For Loop

Create an output list and run a for loop

```{r}
output <- vector("list", length = 4)

for (i in 1:4) {
  
  output[[i]] = mean_and_sd(list_norm[[i]])
  
}

output
```

# Use Map

```{r}
output <- map(list_norm, mean_and_sd)
```

# Other things

```{r}
output <- map(list_norm, mean_and_sd) %>% 
  bind_rows()

output <- map_dfr(list_norm, mean_and_sd)

output <- map_dbl(list_norm, IQR)
```


# List Columns 

```{r}
listcol_df <- 
  tibble(
    name = c("a","b", "c", "d"), 
    samp = list_norm
  )

listcol_df %>% 
  filter(name %in% c("a", "b")) 

listcol_df %>% 
  select(-samp)
```

```{r}
listcol_df[["samp"]][["a"]]
```

Compute Mean and Standard Deviation

```{r}
mean_and_sd(listcol_df[["samp"]][["a"]])
mean_and_sd(listcol_df[["samp"]][["b"]])

map(listcol_df[["samp"]], mean_and_sd)
```

Add a list column 

```{r}
listcol_df %>% 
  mutate(output = map(samp, mean_and_sd), 
         iqr = map_dbl(samp, IQR))

listcol_df %>% 
  mutate(output = map(samp, mean_and_sd), 
         iqr = map_dbl(samp, IQR)) %>% 
  select(-samp) %>% 
  unnest(output)
```

## NSDUH

```{r}
nsduh_import <- function(html, table) {
  
  output_df <-
    html %>% 
    html_table() %>% 
    nth(table) %>%  
    slice(-1) %>% 
    select(-contains("P Value"))
  
  return(output_df)
}


```

Writing a function to get each table. 

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

nsduh_html <- read_html(url)

nsduh_import(nsduh_html, 1)
nsduh_import(nsduh_html, 4)
nsduh_import(nsduh_html, 5)

nsduh_df <- 
  tibble(
    drug = c("marj", "cocaine", "heroine"), 
    table_n = c(1, 4, 5)) %>% 
      mutate(table = map(table_n, \(x)nsduh_import(nsduh_html, x))) %>% 
  unnest(table)

nsduh_df %>% 
  filter(State == "New York") 
```

# Weather Data

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USW00022534", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2021-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(
      id, 
      USW00094728 = "CentralPark_NY", 
      USW00022534 = "Molokai_HI",
      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

Create a list column

```{r}
weather_nest <- 
  weather_df %>% 
  nest(data = date:tmin) 
```

```{r}
weather_nest[["data"]][1]
```

Regression with tmax and tmin

```{r}
lm(tmax ~ tmin, data = weather_nest[["data"]][[1]])
lm(tmax ~ tmin, data = weather_nest[["data"]][[2]])
lm(tmax ~ tmin, data = weather_nest[["data"]][[3]])
```

```{r}
weather_nest %>% 
  mutate(model_fit = map(data, \(x) lm(tmax ~ tmin, data = x))) %>% 
  pull(model_fit)
```

